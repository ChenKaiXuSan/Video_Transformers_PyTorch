{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Walk_Video_PyTorch/project\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "%cd /workspace/Walk_Video_PyTorch/project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pytorchvideo_models import WalkVideoClassificationLightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--model {resnet,csn}] [--img_size IMG_SIZE]\n",
      "                             [--version VERSION]\n",
      "                             [--model_class_num MODEL_CLASS_NUM]\n",
      "                             [--model_depth {50,101,152}]\n",
      "                             [--max_epochs MAX_EPOCHS]\n",
      "                             [--batch_size BATCH_SIZE]\n",
      "                             [--num_workers NUM_WORKERS]\n",
      "                             [--clip_duration CLIP_DURATION]\n",
      "                             [--uniform_temporal_subsample_num UNIFORM_TEMPORAL_SUBSAMPLE_NUM]\n",
      "                             [--gpu_num {0,1}]\n",
      "                             [--fusion_method {single_frame,early_fusion,late_fusion,slow_fusion}]\n",
      "                             [--pre_process_flag] [--transfor_learning]\n",
      "                             [--fix_layer {all,head,stem_head,stage_head}]\n",
      "                             [--lr LR] [--beta1 BETA1] [--beta2 BETA2]\n",
      "                             [--data_path DATA_PATH]\n",
      "                             [--split_data_path SPLIT_DATA_PATH]\n",
      "                             [--split_pad_data_path SPLIT_PAD_DATA_PATH]\n",
      "                             [--log_path LOG_PATH]\n",
      "                             [--pretrained_model PRETRAINED_MODEL]\n",
      "ipykernel_launcher.py: error: ambiguous option: --f=/root/.local/share/jupyter/runtime/kernel-v2-5869240NQT7ipZ9TN5.json could match --fusion_method, --fix_layer\n",
      "100.51s - Error processing internal command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/debugpy/_vendored/pydevd/pydevd.py\", line 1772, in process_internal_commands\n",
      "    int_cmd.do_it(self)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_comm.py\", line 527, in do_it\n",
      "    self.method(dbg, *self.args, **self.kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_comm.py\", line 1165, in internal_evaluate_expression_json\n",
      "    eval_result = pydevd_vars.evaluate_expression(py_db, frame, expression, is_exec=False)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_vars.py\", line 370, in new_func\n",
      "    return _run_with_unblock_threads(original_func, py_db, curr_thread, frame, expression, is_exec)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_vars.py\", line 334, in _run_with_unblock_threads\n",
      "    return _run_with_interrupt_thread(original_func, py_db, curr_thread, frame, expression, is_exec)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_vars.py\", line 305, in _run_with_interrupt_thread\n",
      "    return original_func(py_db, frame, expression, is_exec)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_vars.py\", line 576, in evaluate_expression\n",
      "    ret = eval_in_context(expression, updated_globals, updated_locals, py_db)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_vars.py\", line 268, in eval_in_context\n",
      "    result = eval(compiled, global_vars, local_vars)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 1870, in parse_known_args\n",
      "    namespace, args = self._parse_known_args(args, namespace)\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 1914, in _parse_known_args\n",
      "    option_tuple = self._parse_optional(arg_string)\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 2230, in _parse_optional\n",
      "    self.error(msg % args)\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 2594, in error\n",
      "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 2581, in exit\n",
      "    _sys.exit(status)\n",
      "SystemExit: 2\n"
     ]
    }
   ],
   "source": [
    "from main import get_parameters\n",
    "\n",
    "opt = get_parameters().parse_known_args()\n",
    "opt.num_workers = 8\n",
    "opt.batch_size = 8\n",
    "\n",
    "opt.version = '1114_1_16'\n",
    "opt.model = \"resnet\"\n",
    "opt.model_depth = 50\n",
    "opt.model_class_num = 1\n",
    "\n",
    "opt.clip_duraion = 1\n",
    "opt.uniform_temporal_subsample_num = 16\n",
    "opt.version = opt.version + '_' + opt.model + '_depth' + str(opt.model_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n",
      "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Walk_Video_PyTorch/logs/resnet/0902_1_16_resnet_depth50/checkpoints/epoch=7-val_loss=0.89-val_acc=0.7215.ckpt\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import get_ckpt_path\n",
    "\n",
    "model = WalkVideoClassificationLightningModule(opt)\n",
    "\n",
    "# get last ckpt path\n",
    "# ckpt_path = get_ckpt_path(opt)\n",
    "\n",
    "ckpt_path = '/workspace/Walk_Video_PyTorch/logs/resnet/0902_1_16_resnet_depth50/checkpoints/epoch=7-val_loss=0.89-val_acc=0.7215.ckpt'\n",
    "\n",
    "# model = WalkVideoClassificationLightningModule.load_from_checkpoint(ckpt_path)\n",
    "# model.load_state_dict(weight)\n",
    "model = model.load_from_checkpoint(ckpt_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# clear_output()\n",
    "print(ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.data_loader import WalkDataModule\n",
    "from pytorch_lightning import loggers as pl_loggers \n",
    "\n",
    "# load test dataset \n",
    "module = WalkDataModule(opt)\n",
    "module.setup()\n",
    "test_data = module.test_dataloader()\n",
    "\n",
    "# for the tensorboard\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"/workspace/Walk_Video_PyTorch/project/tests/logs\", name=opt.model, version=opt.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at /workspace/Walk_Video_PyTorch/logs/resnet/0902_1_16_resnet_depth50/checkpoints/epoch=7-val_loss=0.89-val_acc=0.7215.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "Loaded model weights from checkpoint at /workspace/Walk_Video_PyTorch/logs/resnet/0902_1_16_resnet_depth50/checkpoints/epoch=7-val_loss=0.89-val_acc=0.7215.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23bb300924c47d584698188e807d105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7426, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7397260069847107     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_average_precision   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7818960547447205     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7397260069847107    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_average_precision  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7818960547447205    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.7818960547447205,\n",
       "  'test_acc': 0.7397260069847107,\n",
       "  'test_average_precision': nan}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[1,],\n",
    "    gpus=opt.gpu_num,\n",
    "    logger=tb_logger,\n",
    "    max_epochs=1,\n",
    "    # deterministic=True,\n",
    ")\n",
    "\n",
    "trainer.test(dataloaders=module, model=model, ckpt_path=ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = next(iter(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20211221_ASD_lat_V1-0007.mp4',\n",
       " '20210518_1_ASD_lat_V1-0006.mp4',\n",
       " '20210812_DHS_lat_V1-0023.mp4',\n",
       " '20210309_ASD_lat__V1-0037.mp4']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data['video'].shape\n",
    "\n",
    "input_data[\"video_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(input_data['video'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 1, 0]),\n",
       " tensor([[-4.1151],\n",
       "         [-8.6586],\n",
       "         [11.3148],\n",
       "         [-2.1958]], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label = input_data['label']\n",
    "pred_label = preds\n",
    "\n",
    "real_label, pred_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1596399/3629341915.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sigmoid(pred_label), tanh(pred_label), softmax(pred_label)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.6062e-02],\n",
       "         [1.7360e-04],\n",
       "         [9.9999e-01],\n",
       "         [1.0013e-01]], grad_fn=<SigmoidBackward0>),\n",
       " tensor([[-0.9995],\n",
       "         [-1.0000],\n",
       "         [ 1.0000],\n",
       "         [-0.9755]], grad_fn=<TanhBackward0>),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import sigmoid, tanh, softmax\n",
    "\n",
    "sigmoid(pred_label), tanh(pred_label), softmax(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[1.6062e-02],\n",
       "        [1.7360e-04],\n",
       "        [9.9999e-01],\n",
       "        [1.0013e-01]], grad_fn=<TopkBackward0>),\n",
       "indices=tensor([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_pred = sigmoid(pred_label)\n",
    "\n",
    "sigmoid_pred.topk(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6389)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.metrics import get_Accuracy, get_Average_precision\n",
    "\n",
    "accuracy = get_Accuracy(1)\n",
    "AP = get_Average_precision(1)\n",
    "\n",
    "accuracy(preds.squeeze(), input_data['label'])\n",
    "AP(preds.squeeze(), input_data['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
